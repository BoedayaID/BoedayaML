{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python391jvsc74a57bd0559daca3eafdbd1bef4f08433f5f56541036d82cc701707d10377dcc6e3b7299",
   "display_name": "Python 3.9.1 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = \"dataset.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of datasets:  120\n"
     ]
    }
   ],
   "source": [
    "#Loading the dataset\n",
    "\n",
    "with open(DATASET_PATH, \"r\") as fp:\n",
    "    data = json.load(fp)\n",
    "X = np.array(data['MFCCs'])\n",
    "y = np.array(data['labels'])\n",
    "print(\"Number of datasets: \", len(X) if len(X)==len(y) else \"Number of MFCCs and labels don't match\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(126, 13, 1)\n"
     ]
    }
   ],
   "source": [
    "#Training, test, and validation data splitting\n",
    "\n",
    "Xtr, Xt, ytr, yt = train_test_split(X, y, test_size=0.1)\n",
    "Xtr, Xval, ytr, yval = train_test_split(Xtr, ytr, test_size=0.1)\n",
    "\n",
    "Xtr = Xtr[..., np.newaxis]\n",
    "Xt = Xt[..., np.newaxis]\n",
    "Xval = Xval[..., np.newaxis]\n",
    "\n",
    "input_shape = (Xtr.shape[1], Xtr.shape[2], 1)\n",
    "print(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "      def on_epoch_end(self, epoch, logs={}):\n",
    "        if(logs.get('val_accuracy')>0.8):\n",
    "          self.model.stop_training = True\n",
    "\n",
    "callbacks = myCallback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_10\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_26 (Conv2D)           (None, 124, 11, 64)       640       \n_________________________________________________________________\nbatch_normalization_26 (Batc (None, 124, 11, 64)       256       \n_________________________________________________________________\nmax_pooling2d_26 (MaxPooling (None, 62, 6, 64)         0         \n_________________________________________________________________\ndropout_35 (Dropout)         (None, 62, 6, 64)         0         \n_________________________________________________________________\nconv2d_27 (Conv2D)           (None, 60, 4, 32)         18464     \n_________________________________________________________________\nbatch_normalization_27 (Batc (None, 60, 4, 32)         128       \n_________________________________________________________________\nmax_pooling2d_27 (MaxPooling (None, 30, 2, 32)         0         \n_________________________________________________________________\ndropout_36 (Dropout)         (None, 30, 2, 32)         0         \n_________________________________________________________________\nconv2d_28 (Conv2D)           (None, 29, 1, 32)         4128      \n_________________________________________________________________\nbatch_normalization_28 (Batc (None, 29, 1, 32)         128       \n_________________________________________________________________\nmax_pooling2d_28 (MaxPooling (None, 15, 1, 32)         0         \n_________________________________________________________________\ndropout_37 (Dropout)         (None, 15, 1, 32)         0         \n_________________________________________________________________\nflatten_10 (Flatten)         (None, 480)               0         \n_________________________________________________________________\ndense_20 (Dense)             (None, 32)                15392     \n_________________________________________________________________\ndropout_38 (Dropout)         (None, 32)                0         \n_________________________________________________________________\ndense_21 (Dense)             (None, 10)                330       \n=================================================================\nTotal params: 39,466\nTrainable params: 39,210\nNon-trainable params: 256\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    layers.Conv2D(64, (3, 3), activation='relu', input_shape=input_shape, kernel_regularizer=tf.keras.regularizers.l1(0.001)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D((3, 3), strides=(2,2), padding='same'),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D((3, 3), strides=(2,2), padding='same'),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Conv2D(32, (2, 2), activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D((3, 3), strides=(2,2), padding='same'),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.SGD(learning_rate=10e-3),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/10000\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.2996 - accuracy: 0.9794 - val_loss: 2.5316 - val_accuracy: 0.4545\n",
      "Epoch 9352/10000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.3198 - accuracy: 0.9691 - val_loss: 2.6111 - val_accuracy: 0.4545\n",
      "Epoch 9353/10000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.3463 - accuracy: 0.9485 - val_loss: 2.6261 - val_accuracy: 0.4545\n",
      "Epoch 9354/10000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.2863 - accuracy: 0.9897 - val_loss: 2.7122 - val_accuracy: 0.4545\n",
      "Epoch 9355/10000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.3293 - accuracy: 0.9588 - val_loss: 2.6785 - val_accuracy: 0.4545\n",
      "Epoch 9356/10000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.3045 - accuracy: 0.9794 - val_loss: 2.7415 - val_accuracy: 0.4545\n",
      "Epoch 9357/10000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.2689 - accuracy: 0.9897 - val_loss: 2.9133 - val_accuracy: 0.3636\n",
      "Epoch 9358/10000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.2902 - accuracy: 0.9897 - val_loss: 2.8849 - val_accuracy: 0.3636\n",
      "Epoch 9359/10000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.2868 - accuracy: 0.9897 - val_loss: 2.9024 - val_accuracy: 0.3636\n",
      "Epoch 9360/10000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.2575 - accuracy: 1.0000 - val_loss: 2.8818 - val_accuracy: 0.3636\n",
      "Epoch 9361/10000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.3493 - accuracy: 0.9588 - val_loss: 2.8864 - val_accuracy: 0.3636\n",
      "Epoch 9362/10000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.3065 - accuracy: 0.9794 - val_loss: 2.8403 - val_accuracy: 0.3636\n",
      "Epoch 9363/10000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.2766 - accuracy: 0.9897 - val_loss: 2.8384 - val_accuracy: 0.3636\n",
      "Epoch 9364/10000\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.3369 - accuracy: 0.9691 - val_loss: 2.9055 - val_accuracy: 0.3636\n",
      "Epoch 9365/10000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.3445 - accuracy: 0.9588 - val_loss: 2.9464 - val_accuracy: 0.3636\n",
      "Epoch 9366/10000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.2936 - accuracy: 0.9897 - val_loss: 2.9730 - val_accuracy: 0.3636\n",
      "Epoch 9367/10000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.3674 - accuracy: 0.9794 - val_loss: 2.8962 - val_accuracy: 0.3636\n",
      "Epoch 9368/10000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.3202 - accuracy: 0.9691 - val_loss: 2.8728 - val_accuracy: 0.3636\n",
      "Epoch 9369/10000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.3195 - accuracy: 0.9794 - val_loss: 2.8612 - val_accuracy: 0.4545\n",
      "Epoch 9370/10000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.3132 - accuracy: 0.9794 - val_loss: 2.8514 - val_accuracy: 0.4545\n",
      "Epoch 9371/10000\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.3011 - accuracy: 0.9794 - val_loss: 2.8646 - val_accuracy: 0.4545\n",
      "Epoch 9372/10000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.3453 - accuracy: 0.9691 - val_loss: 2.8012 - val_accuracy: 0.4545\n",
      "Epoch 9373/10000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.3052 - accuracy: 0.9794 - val_loss: 2.7777 - val_accuracy: 0.4545\n",
      "Epoch 9374/10000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.3413 - accuracy: 0.9691 - val_loss: 2.7722 - val_accuracy: 0.4545\n",
      "Epoch 9375/10000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.3698 - accuracy: 0.9381 - val_loss: 2.8200 - val_accuracy: 0.4545\n",
      "Epoch 9376/10000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.3096 - accuracy: 0.9794 - val_loss: 2.7569 - val_accuracy: 0.4545\n",
      "Epoch 9377/10000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.2621 - accuracy: 1.0000 - val_loss: 2.7416 - val_accuracy: 0.4545\n",
      "Epoch 9378/10000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.2985 - accuracy: 0.9897 - val_loss: 2.7215 - val_accuracy: 0.4545\n",
      "Epoch 9379/10000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.3214 - accuracy: 0.9691 - val_loss: 2.6941 - val_accuracy: 0.4545\n",
      "Epoch 9380/10000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.3004 - accuracy: 0.9897 - val_loss: 2.7024 - val_accuracy: 0.4545\n",
      "Epoch 9381/10000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.2909 - accuracy: 0.9794 - val_loss: 2.7244 - val_accuracy: 0.4545\n",
      "Epoch 9382/10000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.2740 - accuracy: 0.9897 - val_loss: 2.7171 - val_accuracy: 0.4545\n",
      "Epoch 9383/10000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.3017 - accuracy: 0.9794 - val_loss: 3.2258 - val_accuracy: 0.2727\n",
      "Epoch 9384/10000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.3937 - accuracy: 0.9588 - val_loss: 3.1983 - val_accuracy: 0.2727\n",
      "Epoch 9385/10000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.2742 - accuracy: 0.9897 - val_loss: 2.5222 - val_accuracy: 0.4545\n",
      "Epoch 9386/10000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.3744 - accuracy: 0.9691 - val_loss: 2.5103 - val_accuracy: 0.4545\n",
      "Epoch 9387/10000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.2651 - accuracy: 1.0000 - val_loss: 2.5151 - val_accuracy: 0.3636\n",
      "Epoch 9388/10000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.3247 - accuracy: 0.9691 - val_loss: 2.5745 - val_accuracy: 0.4545\n",
      "Epoch 9389/10000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.2741 - accuracy: 0.9794 - val_loss: 2.5850 - val_accuracy: 0.4545\n",
      "Epoch 9390/10000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.3144 - accuracy: 0.9691 - val_loss: 2.5718 - val_accuracy: 0.4545\n",
      "Epoch 9391/10000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.3193 - accuracy: 0.9691 - val_loss: 2.5648 - val_accuracy: 0.4545\n",
      "Epoch 9392/10000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.2796 - accuracy: 1.0000 - val_loss: 2.5638 - val_accuracy: 0.4545\n",
      "Epoch 9393/10000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.2760 - accuracy: 0.9897 - val_loss: 2.5933 - val_accuracy: 0.4545\n",
      "Epoch 9394/10000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.3529 - accuracy: 0.9691 - val_loss: 2.6343 - val_accuracy: 0.4545\n",
      "Epoch 9395/10000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.3377 - accuracy: 0.9588 - val_loss: 2.5396 - val_accuracy: 0.4545\n",
      "Epoch 9396/10000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.3349 - accuracy: 0.9588 - val_loss: 2.5343 - val_accuracy: 0.4545\n",
      "Epoch 9397/10000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.2773 - accuracy: 0.9794 - val_loss: 2.5391 - val_accuracy: 0.4545\n",
      "Epoch 9398/10000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.3409 - accuracy: 0.9794 - val_loss: 2.5232 - val_accuracy: 0.4545\n",
      "Epoch 9399/10000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.2702 - accuracy: 0.9897 - val_loss: 2.5119 - val_accuracy: 0.4545\n",
      "Epoch 9400/10000\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.3014 - accuracy: 0.9691 - val_loss: 2.5050 - val_accuracy: 0.4545\n",
      "Epoch 9401/10000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.2666 - accuracy: 1.0000 - val_loss: 2.5379 - val_accuracy: 0.4545\n",
      "Epoch 9402/10000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.3283 - accuracy: 0.9691 - val_loss: 2.5465 - val_accuracy: 0.3636\n",
      "Epoch 9403/10000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.3229 - accuracy: 0.9691 - val_loss: 2.5098 - val_accuracy: 0.3636\n",
      "Epoch 9404/10000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.3357 - accuracy: 0.9691 - val_loss: 2.5330 - val_accuracy: 0.3636\n",
      "Epoch 9405/10000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.2770 - accuracy: 0.9897 - val_loss: 2.5137 - val_accuracy: 0.3636\n",
      "Epoch 9406/10000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.3103 - accuracy: 0.9794 - val_loss: 2.5338 - val_accuracy: 0.4545\n",
      "Epoch 9407/10000\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.2927 - accuracy: 0.9691 - val_loss: 2.5274 - val_accuracy: 0.4545\n",
      "Epoch 9408/10000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.3568 - accuracy: 0.9588 - val_loss: 2.5188 - val_accuracy: 0.4545\n",
      "Epoch 9409/10000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.2951 - accuracy: 0.9794 - val_loss: 2.5206 - val_accuracy: 0.4545\n",
      "Epoch 9410/10000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.2979 - accuracy: 0.9897 - val_loss: 2.5442 - val_accuracy: 0.4545\n",
      "Epoch 9411/10000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.3211 - accuracy: 0.9691 - val_loss: 2.5424 - val_accuracy: 0.4545\n",
      "Epoch 9412/10000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.2697 - accuracy: 1.0000 - val_loss: 2.5811 - val_accuracy: 0.4545\n",
      "Epoch 9413/10000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.2978 - accuracy: 0.9794 - val_loss: 2.6039 - val_accuracy: 0.4545\n",
      "Epoch 9414/10000\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.3157 - accuracy: 0.9588 - val_loss: 2.6313 - val_accuracy: 0.3636\n",
      "Epoch 9415/10000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.3227 - accuracy: 0.9485 - val_loss: 2.6166 - val_accuracy: 0.3636\n",
      "Epoch 9416/10000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.2777 - accuracy: 0.9897 - val_loss: 2.5736 - val_accuracy: 0.3636\n",
      "Epoch 9417/10000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.3093 - accuracy: 0.9794 - val_loss: 2.5546 - val_accuracy: 0.3636\n",
      "Epoch 9418/10000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.3760 - accuracy: 0.9485 - val_loss: 2.6071 - val_accuracy: 0.3636\n",
      "Epoch 9419/10000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.3372 - accuracy: 0.9588 - val_loss: 2.5147 - val_accuracy: 0.4545\n",
      "Epoch 9420/10000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.3449 - accuracy: 0.9691 - val_loss: 2.4804 - val_accuracy: 0.4545\n",
      "Epoch 9421/10000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.2887 - accuracy: 0.9691 - val_loss: 2.4470 - val_accuracy: 0.4545\n",
      "Epoch 9422/10000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.4775 - accuracy: 0.9278 - val_loss: 2.5758 - val_accuracy: 0.3636\n",
      "Epoch 9423/10000\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.3593 - accuracy: 0.9691 - val_loss: 2.5177 - val_accuracy: 0.4545\n",
      "Epoch 9424/10000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.3302 - accuracy: 0.9588 - val_loss: 2.4586 - val_accuracy: 0.4545\n",
      "Epoch 9425/10000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.2973 - accuracy: 0.9897 - val_loss: 2.4459 - val_accuracy: 0.4545\n",
      "Epoch 9426/10000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.3585 - accuracy: 0.9588 - val_loss: 2.2897 - val_accuracy: 0.5455\n",
      "Epoch 9427/10000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.4145 - accuracy: 0.9588 - val_loss: 2.2939 - val_accuracy: 0.5455\n",
      "Epoch 9428/10000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.3242 - accuracy: 0.9691 - val_loss: 2.2996 - val_accuracy: 0.5455\n",
      "Epoch 9429/10000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.2770 - accuracy: 1.0000 - val_loss: 2.3012 - val_accuracy: 0.5455\n",
      "Epoch 9430/10000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.3024 - accuracy: 0.9794 - val_loss: 2.3267 - val_accuracy: 0.5455\n",
      "Epoch 9431/10000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.4101 - accuracy: 0.8969 - val_loss: 2.3017 - val_accuracy: 0.5455\n",
      "Epoch 9432/10000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.4061 - accuracy: 0.9485 - val_loss: 2.2318 - val_accuracy: 0.5455\n",
      "Epoch 9433/10000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.5016 - accuracy: 0.9072 - val_loss: 2.2296 - val_accuracy: 0.5455\n",
      "Epoch 9434/10000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.3142 - accuracy: 0.9691 - val_loss: 2.2289 - val_accuracy: 0.5455\n",
      "Epoch 9435/10000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.3355 - accuracy: 0.9588 - val_loss: 2.2740 - val_accuracy: 0.5455\n",
      "Epoch 9436/10000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.2746 - accuracy: 0.9897 - val_loss: 2.2904 - val_accuracy: 0.5455\n",
      "Epoch 9437/10000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.2784 - accuracy: 0.9794 - val_loss: 2.2999 - val_accuracy: 0.5455\n",
      "Epoch 9438/10000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.3313 - accuracy: 0.9691 - val_loss: 2.3552 - val_accuracy: 0.5455\n",
      "Epoch 9439/10000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.2746 - accuracy: 0.9897 - val_loss: 2.3697 - val_accuracy: 0.5455\n",
      "Epoch 9440/10000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.3119 - accuracy: 0.9691 - val_loss: 2.7640 - val_accuracy: 0.4545\n",
      "Epoch 9441/10000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.2897 - accuracy: 0.9691 - val_loss: 2.7290 - val_accuracy: 0.4545\n",
      "Epoch 9442/10000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.3254 - accuracy: 0.9794 - val_loss: 2.7289 - val_accuracy: 0.4545\n",
      "Epoch 9443/10000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.3132 - accuracy: 0.9794 - val_loss: 2.7050 - val_accuracy: 0.4545\n",
      "Epoch 9444/10000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.3231 - accuracy: 0.9897 - val_loss: 2.7061 - val_accuracy: 0.4545\n",
      "Epoch 9445/10000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.3462 - accuracy: 0.9485 - val_loss: 2.6909 - val_accuracy: 0.4545\n",
      "Epoch 9446/10000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.2622 - accuracy: 1.0000 - val_loss: 2.6666 - val_accuracy: 0.4545\n",
      "Epoch 9447/10000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.2612 - accuracy: 1.0000 - val_loss: 2.6656 - val_accuracy: 0.4545\n",
      "Epoch 9448/10000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.2998 - accuracy: 0.9691 - val_loss: 2.6566 - val_accuracy: 0.4545\n",
      "Epoch 9449/10000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.2764 - accuracy: 0.9897 - val_loss: 2.6464 - val_accuracy: 0.4545\n",
      "Epoch 9450/10000\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.3319 - accuracy: 0.9485 - val_loss: 2.6900 - val_accuracy: 0.4545\n",
      "Epoch 9451/10000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.3572 - accuracy: 0.9794 - val_loss: 2.6348 - val_accuracy: 0.4545\n",
      "Epoch 9452/10000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.3611 - accuracy: 0.9588 - val_loss: 2.6287 - val_accuracy: 0.5455\n",
      "Epoch 9453/10000\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.2876 - accuracy: 0.9794 - val_loss: 2.6173 - val_accuracy: 0.5455\n",
      "Epoch 9454/10000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.3748 - accuracy: 0.9588 - val_loss: 2.5699 - val_accuracy: 0.5455\n",
      "Epoch 9455/10000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.2841 - accuracy: 0.9897 - val_loss: 2.5502 - val_accuracy: 0.5455\n",
      "Epoch 9456/10000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.2820 - accuracy: 0.9897 - val_loss: 2.5399 - val_accuracy: 0.5455\n",
      "Epoch 9457/10000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.2884 - accuracy: 0.9794 - val_loss: 2.5476 - val_accuracy: 0.5455\n",
      "Epoch 9458/10000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.3119 - accuracy: 0.9691 - val_loss: 2.5509 - val_accuracy: 0.5455\n",
      "Epoch 9459/10000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.3000 - accuracy: 0.9691 - val_loss: 2.5572 - val_accuracy: 0.6364\n",
      "Epoch 9460/10000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.2739 - accuracy: 0.9897 - val_loss: 2.5740 - val_accuracy: 0.5455\n",
      "Epoch 9461/10000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.3184 - accuracy: 0.9794 - val_loss: 2.5394 - val_accuracy: 0.5455\n",
      "Epoch 9462/10000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.3112 - accuracy: 0.9691 - val_loss: 2.5001 - val_accuracy: 0.5455\n",
      "Epoch 9463/10000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.3800 - accuracy: 0.9588 - val_loss: 2.5160 - val_accuracy: 0.5455\n",
      "Epoch 9464/10000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.3209 - accuracy: 0.9794 - val_loss: 2.5246 - val_accuracy: 0.5455\n",
      "Epoch 9465/10000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.2733 - accuracy: 0.9897 - val_loss: 2.5325 - val_accuracy: 0.5455\n",
      "Epoch 9466/10000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.2927 - accuracy: 0.9794 - val_loss: 2.5750 - val_accuracy: 0.5455\n",
      "Epoch 9467/10000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.3167 - accuracy: 0.9691 - val_loss: 2.5545 - val_accuracy: 0.6364\n",
      "Epoch 9468/10000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.2770 - accuracy: 0.9897 - val_loss: 2.5649 - val_accuracy: 0.6364\n",
      "Epoch 9469/10000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.2754 - accuracy: 0.9897 - val_loss: 2.5517 - val_accuracy: 0.6364\n",
      "Epoch 9470/10000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.3140 - accuracy: 0.9794 - val_loss: 2.5472 - val_accuracy: 0.6364\n",
      "Epoch 9471/10000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.3043 - accuracy: 0.9691 - val_loss: 2.5432 - val_accuracy: 0.6364\n",
      "Epoch 9472/10000\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.3529 - accuracy: 0.9588 - val_loss: 2.5174 - val_accuracy: 0.6364\n",
      "Epoch 9473/10000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.3501 - accuracy: 0.9588 - val_loss: 2.4622 - val_accuracy: 0.6364\n",
      "Epoch 9474/10000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.2981 - accuracy: 0.9794 - val_loss: 2.7668 - val_accuracy: 0.5455\n",
      "Epoch 9475/10000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.2638 - accuracy: 0.9897 - val_loss: 2.7594 - val_accuracy: 0.5455\n",
      "Epoch 9476/10000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.3264 - accuracy: 0.9588 - val_loss: 2.7768 - val_accuracy: 0.5455\n",
      "Epoch 9477/10000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.3229 - accuracy: 0.9485 - val_loss: 2.7853 - val_accuracy: 0.5455\n",
      "Epoch 9478/10000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.2741 - accuracy: 1.0000 - val_loss: 2.7743 - val_accuracy: 0.5455\n",
      "Epoch 9479/10000\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.3033 - accuracy: 0.9691 - val_loss: 2.6897 - val_accuracy: 0.5455\n",
      "Epoch 9480/10000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.3078 - accuracy: 0.9897 - val_loss: 2.6482 - val_accuracy: 0.5455\n",
      "Epoch 9481/10000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.2918 - accuracy: 0.9691 - val_loss: 2.6266 - val_accuracy: 0.5455\n",
      "Epoch 9482/10000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.2998 - accuracy: 0.9794 - val_loss: 2.4686 - val_accuracy: 0.6364\n",
      "Epoch 9483/10000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.3454 - accuracy: 0.9588 - val_loss: 2.4857 - val_accuracy: 0.6364\n",
      "Epoch 9484/10000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.2864 - accuracy: 0.9691 - val_loss: 2.5293 - val_accuracy: 0.6364\n",
      "Epoch 9485/10000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.2933 - accuracy: 0.9897 - val_loss: 2.5099 - val_accuracy: 0.6364\n",
      "Epoch 9486/10000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.2818 - accuracy: 0.9897 - val_loss: 2.5538 - val_accuracy: 0.6364\n",
      "Epoch 9487/10000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.3477 - accuracy: 0.9485 - val_loss: 2.5738 - val_accuracy: 0.6364\n",
      "Epoch 9488/10000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.4360 - accuracy: 0.9381 - val_loss: 2.3116 - val_accuracy: 0.8182\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    Xtr,\n",
    "    ytr,\n",
    "    epochs=10000,\n",
    "    validation_data=(Xval, yval),\n",
    "    callbacks=[callbacks]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model.h5\")"
   ]
  }
 ]
}